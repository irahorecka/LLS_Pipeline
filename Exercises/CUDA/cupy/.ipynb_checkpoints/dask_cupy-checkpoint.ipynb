{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Dask arrays and CuPy together - a tutorial\n",
    "https://matthewrocklin.com/blog//work/2019/01/03/dask-array-gpus-first-steps\n",
    "\n",
    "2020-02-03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. CuPy provides a partial implementation of Numpy on the GPU.\n",
    "\n",
    "2. Dask Array provides chunked algorithms on top of Numpy-like libraries like Numpy and CuPy.<br>\n",
    "    This enables us to operate on more data than we could fit in memory by operating on that data in chunks.\n",
    "\n",
    "3. The Dask distributed task scheduler runs those algorithms in parallel, easily coordinating work across many CPU cores or GPUs.\n",
    "\n",
    "<br>\n",
    "These libraries allow us to quickly judge the costs of this computation for the following hardware choices:\n",
    "\n",
    "1. Single-threaded CPU\n",
    "2. Multi-threaded CPU with 40 cores (80 H/T)\n",
    "3. Single-GPU\n",
    "4. Multi-GPU on a single machine with 8 GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000.0\n"
     ]
    }
   ],
   "source": [
    "import cupy\n",
    "import dask.array as da\n",
    "\n",
    "# THIS IS FOR CPU COMPUTATION\n",
    "\n",
    "# generate chunked dask arrays of mamy numpy random arrays\n",
    "rs = da.random.RandomState()\n",
    "x = rs.normal(10, 1, size=(500000, 500000), chunks=(10000, 10000))\n",
    "\n",
    "print(x.nbytes / 1e9)  # 2 TB\n",
    "# 2000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip due to high computation time\n",
    "\n",
    "# Single CPU timing\n",
    "# (x + 1)[::2, ::2].sum().compute(scheduler='single-threaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi CPU timing\n",
    "# (x + 1)[::2, ::2].sum().compute(scheduler='threads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS FOR GPU COMPUTATION\n",
    "\n",
    "# make sure to pip install dask-cuda prior to import\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "\n",
    "cluster = LocalCUDACluster()\n",
    "client = Client(cluster)\n",
    "# retrieve client server for viewing\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate chunked dask arrays of mamy cupy random arrays\n",
    "rs = da.random.RandomState(RandomState=cupy.random.RandomState)  # <-- we specify cupy here\n",
    "x = rs.normal(10, 1, size=(500000, 500000), chunks=(10000, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single GPU timing\n",
    "(x + 1)[::2, ::2].sum().compute(scheduler='single-threaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi GPU timing\n",
    "(x + 1)[::2, ::2].sum().compute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari (venv)",
   "language": "python",
   "name": "napari"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
